{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
    "torch.multiprocessing.set_start_method('spawn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (4.5.3)\n",
      "Requirement already satisfied: requests[socks] in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: six in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: filelock in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from gdown) (3.8.0)\n",
      "Requirement already satisfied: tqdm in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from gdown) (4.64.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from requests[socks]->gdown) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from requests[socks]->gdown) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from requests[socks]->gdown) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from requests[socks]->gdown) (1.26.11)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_id_by_model(folder_name):\n",
    "  file_id = {'resnet18_100-epochs_stl10': '14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF',\n",
    "             'resnet18_100-epochs_cifar10': '1lc2aoVtrAetGn0PnTkOyFzPCIucOJq7C',\n",
    "             'resnet50_50-epochs_stl10': '1ByTKAUsdm_X7tLcii6oAEl5qFRqRMZSu'}\n",
    "  return file_id.get(folder_name, \"Model not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18_100-epochs_stl10 14_nH2FkyKbt61cieQDiSbBVNP8-gtwgF\n"
     ]
    }
   ],
   "source": [
    "folder_name = 'resnet18_100-epochs_stl10'\n",
    "file_id = get_file_id_by_model(folder_name)\n",
    "print(folder_name, file_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # download and extract model files\n",
    "# os.system('gdown --continue https://drive.google.com/uc?id={}'.format(file_id))\n",
    "# os.system('unzip {}'.format(folder_name))\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stl10_data_loaders(download, batch_size=256):\n",
    "  train_dataset = datasets.STL10('./data', split='train', download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=True)\n",
    "  \n",
    "  test_dataset = datasets.STL10('./data', split='test', download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=False)\n",
    "  return train_loader, test_loader\n",
    "\n",
    "def get_cifar10_data_loaders(download, shuffle=False, batch_size=256):\n",
    "  train_dataset = datasets.CIFAR10('./data', train=True, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=True)\n",
    "  \n",
    "  test_dataset = datasets.CIFAR10('./data', train=False, download=download,\n",
    "                                  transform=transforms.ToTensor())\n",
    "\n",
    "  test_loader = DataLoader(test_dataset, batch_size=2*batch_size,\n",
    "                            num_workers=10, drop_last=False, shuffle=False)\n",
    "  return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yaml import BaseLoader, UnsafeLoader\n",
    "with open(os.path.join('./config.yml')) as file:\n",
    "  config = yaml.load(file, Loader=UnsafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/niklas/anaconda3/envs/oads/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "if config.arch == 'resnet18':\n",
    "  model = torchvision.models.resnet18(pretrained=False, num_classes=10).to(device)\n",
    "elif config.arch == 'resnet50':\n",
    "  model = torchvision.models.resnet50(pretrained=False, num_classes=10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('checkpoint_0100.pth.tar', map_location=device)\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "for k in list(state_dict.keys()):\n",
    "\n",
    "  if k.startswith('backbone.'):\n",
    "    if k.startswith('backbone') and not k.startswith('backbone.fc'):\n",
    "      # remove prefix\n",
    "      state_dict[k[len(\"backbone.\"):]] = state_dict[k]\n",
    "  del state_dict[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = model.load_state_dict(state_dict, strict=False)\n",
    "assert log.missing_keys == ['fc.weight', 'fc.bias']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "sys.path.append('..')\n",
    "from oads_access.oads_access import *\n",
    "\n",
    "home = '../../data/oads/mini_oads_2/'\n",
    "oads = OADS_Access(home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.33s/it]\n"
     ]
    }
   ],
   "source": [
    "# get train, val, test split, using crops if specific size\n",
    "size = (200, 200)\n",
    "train_data, val_data, test_data = oads.get_train_val_test_split(use_crops=True, min_size=size, max_size=size, exclude_oversized_crops=True, file_formats=['.jpg'])\n",
    "input_channels = np.array(train_data[0][0]).shape[-1]\n",
    "\n",
    "output_channels = len(oads.get_class_mapping())\n",
    "class_index_mapping = {key: index for index, key in enumerate(list(oads.get_class_mapping().keys()))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_workers = 6\n",
    "\n",
    "# Get the custom dataset and dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "traindataset = OADSImageDataset(data=train_data, class_index_mapping=class_index_mapping, transform=transform, device=device)\n",
    "valdataset = OADSImageDataset(data=val_data, class_index_mapping=class_index_mapping, transform=transform, device=device)\n",
    "testdataset = OADSImageDataset(data=test_data, class_index_mapping=class_index_mapping, transform=transform, device=device)\n",
    "\n",
    "train_loader = DataLoader(traindataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader = DataLoader(valdataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(testdataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers but the last fc\n",
    "for name, param in model.named_parameters():\n",
    "    if name not in ['fc.weight', 'fc.bias']:\n",
    "        param.requires_grad = False\n",
    "\n",
    "parameters = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "assert len(parameters) == 2  # fc.weight, fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003, weight_decay=0.0008)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/niklas/projects/oads_access/notebooks/simclr_test.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/niklas/projects/oads_access/notebooks/simclr_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m x_batch \u001b[39m=\u001b[39m x_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/niklas/projects/oads_access/notebooks/simclr_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/niklas/projects/oads_access/notebooks/simclr_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m logits \u001b[39m=\u001b[39m model(x_batch)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/niklas/projects/oads_access/notebooks/simclr_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logits, y_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/niklas/projects/oads_access/notebooks/simclr_test.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m top1 \u001b[39m=\u001b[39m accuracy(logits, y_batch, topk\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m,))\n",
      "File \u001b[0;32m~/anaconda3/envs/oads/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/oads/lib/python3.9/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/oads/lib/python3.9/site-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[39m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m    269\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/oads/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/oads/lib/python3.9/site-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/anaconda3/envs/oads/lib/python3.9/site-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    454\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "  top1_train_accuracy = 0\n",
    "  for counter, (x_batch, y_batch) in enumerate(train_loader):\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    logits = model(x_batch)\n",
    "    loss = criterion(logits, y_batch)\n",
    "    \n",
    "    top1 = accuracy(logits, y_batch, topk=(1,))\n",
    "    top1_train_accuracy += top1[0]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "  top1_train_accuracy /= (counter + 1)\n",
    "  top1_accuracy = 0\n",
    "  top5_accuracy = 0\n",
    "  \n",
    "  for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    logits = model(x_batch)\n",
    "  \n",
    "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "    top1_accuracy += top1[0]\n",
    "    top5_accuracy += top5[0]\n",
    "  \n",
    "  top1_accuracy /= (counter + 1)\n",
    "  top5_accuracy /= (counter + 1)\n",
    "  print(f\"Epoch {epoch}\\tTop1 Train accuracy {top1_train_accuracy.item()}\\tTop1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top1 Test accuracy: 7.638888835906982\tTop5 test acc: 31.11111068725586\n"
     ]
    }
   ],
   "source": [
    "top1_accuracy = 0\n",
    "top5_accuracy = 0\n",
    "for counter, (x_batch, y_batch) in enumerate(test_loader):\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "\n",
    "    logits = model(x_batch)\n",
    "  \n",
    "    top1, top5 = accuracy(logits, y_batch, topk=(1,5))\n",
    "    top1_accuracy += top1[0]\n",
    "    top5_accuracy += top5[0]\n",
    "  \n",
    "top1_accuracy /= (counter + 1)\n",
    "top5_accuracy /= (counter + 1)\n",
    "print(f\"Top1 Test accuracy: {top1_accuracy.item()}\\tTop5 test acc: {top5_accuracy.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('oads')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35f1b51645cdcbb206d6bffd09b7967f1e22f262807a6af3fb1ff35a1a83c6cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
