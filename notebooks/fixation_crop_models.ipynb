{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from pytorch_utils.pytorch_utils import count_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "home_path = os.path.expanduser('~')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device {device}')\n",
    "\n",
    "model_dir = f'{home_path}/projects/oads_fixation_crop_models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_30000_monotonic_1.0.pth',\n",
       " 'random_5000_monotonic_1.0.pth',\n",
       " 'fixation_30000_monotonic_0.1.pth',\n",
       " 'random_30000_monotonic_0.1.pth',\n",
       " 'fixation_5000_monotonic_0.1.pth',\n",
       " 'fixation_15000_monotonic_1.0.pth',\n",
       " 'fixation_30000_monotonic_1.0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_utils.resnet10 import ResNet10\n",
    "import sys\n",
    "sys.path.append('/home/nmuller/projects/oads-van/_code/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.architecture import ConvVarAutoencoder, VarResNet\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state_dict(state_dict):\n",
    "    from collections import OrderedDict\n",
    "\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in state_dict.items():\n",
    "        if k.startswith('module.'):\n",
    "            name = k[7:]  # remove `module.`\n",
    "        else:\n",
    "            name = k\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VarResNet()\n",
    "model.decoder = nn.Sequential(\n",
    "    nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.ConvTranspose2d(128, 64 , kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.ConvTranspose2d(64 , 32 , kernel_size=4, stride=2, padding=1, bias=False),\n",
    "    nn.ConvTranspose2d(32 , 3  , kernel_size=4, stride=2, padding=1, bias=False),\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = os.path.join(model_dir, f'random_30000_monotonic_1.0.pth')\n",
    "state_dict = convert_state_dict(torch.load(weight_path, map_location=device)['model_state_dict'])\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_forward(self, x):\n",
    "    mu, logvar = self.encode(x)\n",
    "    z = self.reparameterize(mu, logvar)\n",
    "    x_recon = self.decode(z)\n",
    "    return x_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.avgpool = nn.AdaptiveAvgPool2d(output_size=((1, 1)))\n",
    "# self.fc = nn.Linear(in_features=512, out_features=n_output_channels, bias=True)\n",
    "model.decoder = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(output_size=((1, 1))),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=512, out_features=21, bias=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound_method = new_forward.__get__(model, model.__class__)\n",
    "setattr(model, 'forward', bound_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for child in model.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for child in model.decoder.children():\n",
    "    for param in child.parameters():\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10773"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor(np.random.rand(1, 3, 224, 224)).type(torch.DoubleTensor)\n",
    "model = model.type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, torch.Tensor)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out), type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 21])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape#, out[1].shape, out[2].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
